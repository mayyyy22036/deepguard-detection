"""
Script de t√©l√©chargement des datasets de deepfakes
FaceForensics++, Celeb-DF, DFDC
"""

import os
import argparse
import subprocess
import json
from pathlib import Path
from tqdm import tqdm

def download_faceforensics(output_dir, compression="c23", dataset_type="all"):
    """
    T√©l√©charge FaceForensics++
    
    Args:
        output_dir: Dossier de destination
        compression: 'c23' (l√©g√®re) ou 'c40' (forte)
        dataset_type: 'all', 'original', 'Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures'
    
    Note:
        N√©cessite d'avoir re√ßu l'acc√®s au dataset via le formulaire:
        https://github.com/ondyari/FaceForensics/blob/master/dataset/README.md
    """
    print(f"üì• T√©l√©chargement de FaceForensics++ ({compression})...")
    
    # Cr√©er le dossier de destination
    output_path = Path(output_dir) / "faceforensics" / compression
    output_path.mkdir(parents=True, exist_ok=True)
    
    # URL du script de t√©l√©chargement
    download_script_url = "https://raw.githubusercontent.com/ondyari/FaceForensics/master/dataset/download-FaceForensics.py"
    
    print("\n‚ö†Ô∏è  IMPORTANT:")
    print("1. Vous devez d'abord demander l'acc√®s au dataset")
    print("2. Remplir le formulaire: https://github.com/ondyari/FaceForensics")
    print("3. Vous recevrez un email avec vos identifiants")
    print("4. Ensuite, t√©l√©chargez le script officiel et ex√©cutez-le:")
    print(f"\n   wget {download_script_url}")
    print(f"   python download-FaceForensics.py \\")
    print(f"       --output_path {output_path} \\")
    print(f"       --compression {compression} \\")
    print(f"       --dataset {dataset_type}")
    print("\n" + "="*70)
    
    return output_path

def download_celebdf(output_dir):
    """
    T√©l√©charge Celeb-DF v2
    
    Args:
        output_dir: Dossier de destination
    
    Note:
        Acc√®s via: https://github.com/yuezunli/celeb-deepfakeforensics
    """
    print("üì• T√©l√©chargement de Celeb-DF v2...")
    
    output_path = Path(output_dir) / "celeb_df"
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("\n‚ö†Ô∏è  Pour t√©l√©charger Celeb-DF:")
    print("1. Acc√©der √†: https://github.com/yuezunli/celeb-deepfakeforensics")
    print("2. Suivre les instructions pour obtenir l'acc√®s")
    print("3. Utiliser le script de t√©l√©chargement fourni")
    print("\n" + "="*70)
    
    return output_path

def download_dfdc(output_dir):
    """
    T√©l√©charge DFDC Preview Dataset
    
    Args:
        output_dir: Dossier de destination
    
    Note:
        Disponible sur Kaggle: https://www.kaggle.com/c/deepfake-detection-challenge
    """
    print("üì• T√©l√©chargement de DFDC Preview...")
    
    output_path = Path(output_dir) / "dfdc"
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("\n‚ö†Ô∏è  Pour t√©l√©charger DFDC:")
    print("1. Cr√©er un compte Kaggle: https://www.kaggle.com")
    print("2. Installer kaggle CLI: pip install kaggle")
    print("3. Configurer API token: https://www.kaggle.com/docs/api")
    print("4. T√©l√©charger avec:")
    print(f"   kaggle competitions download -c deepfake-detection-challenge -p {output_path}")
    print("\n" + "="*70)
    
    return output_path

def create_dataset_structure(data_dir):
    """
    Cr√©e la structure de dossiers pour les datasets
    """
    structure = {
        "faceforensics": {
            "c23": ["original_sequences", "manipulated_sequences", "splits"],
            "c40": ["original_sequences", "manipulated_sequences", "splits"]
        },
        "celeb_df": ["real", "fake"],
        "dfdc": ["train", "test"]
    }
    
    data_path = Path(data_dir)
    
    for dataset, subdirs in structure.items():
        if isinstance(subdirs, dict):
            for compression, folders in subdirs.items():
                for folder in folders:
                    folder_path = data_path / dataset / compression / folder
                    folder_path.mkdir(parents=True, exist_ok=True)
        else:
            for folder in subdirs:
                folder_path = data_path / dataset / folder
                folder_path.mkdir(parents=True, exist_ok=True)
    
    print(f"‚úÖ Structure de dossiers cr√©√©e dans: {data_path}")

def verify_dataset(dataset_path, dataset_name="faceforensics"):
    """
    V√©rifie l'int√©grit√© du dataset t√©l√©charg√©
    """
    path = Path(dataset_path)
    
    if not path.exists():
        print(f"‚ùå Dataset non trouv√©: {path}")
        return False
    
    if dataset_name == "faceforensics":
        required_dirs = ["original_sequences", "manipulated_sequences"]
        for dir_name in required_dirs:
            dir_path = path / dir_name
            if not dir_path.exists():
                print(f"‚ùå Dossier manquant: {dir_path}")
                return False
        
        # Compter les vid√©os
        video_count = len(list(path.rglob("*.mp4")))
        print(f"‚úÖ Dataset valide - {video_count} vid√©os trouv√©es")
        return True
    
    return True

def main():
    parser = argparse.ArgumentParser(description="T√©l√©chargement des datasets de deepfakes")
    
    parser.add_argument(
        "--dataset",
        type=str,
        choices=["faceforensics", "celebdf", "dfdc", "all"],
        default="faceforensics",
        help="Dataset √† t√©l√©charger"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data",
        help="Dossier de destination"
    )
    
    parser.add_argument(
        "--compression",
        type=str,
        choices=["c23", "c40"],
        default="c23",
        help="Niveau de compression pour FaceForensics++ (c23=l√©ger, c40=fort)"
    )
    
    parser.add_argument(
        "--create_structure",
        action="store_true",
        help="Cr√©er seulement la structure de dossiers"
    )
    
    args = parser.parse_args()
    
    if args.create_structure:
        create_dataset_structure(args.output_dir)
        return
    
    if args.dataset in ["faceforensics", "all"]:
        download_faceforensics(args.output_dir, args.compression)
    
    if args.dataset in ["celebdf", "all"]:
        download_celebdf(args.output_dir)
    
    if args.dataset in ["dfdc", "all"]:
        download_dfdc(args.output_dir)
    
    print("\n‚úÖ Instructions de t√©l√©chargement affich√©es!")
    print("üìù N'oubliez pas de demander l'acc√®s aux datasets avant de t√©l√©charger.")

if __name__ == "__main__":
    main()
